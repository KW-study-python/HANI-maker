# 빈발 항목 집합 찾기

- 메인 메모리의 공간을 효율적으로 사용하는지가 가장 중요하다.
    - 데이터베이스에 빈발 항목 집합이 저장되는 방식
        
        데이터 베이스에 바구니들이 그대로 깔끔하게 들어가는 것이 아니고, 일반적인 파일에 텍스트 형태로 기재된다. 각 아이템들은 고유의 숫자가 할당되어 파일이 기재된다. 장바구니 하나가 끝나면 ‘-1’을 삽입하여 장바구니와 아이템들을 구분해줄 수 있다.(구분자 역할)
        
        ex) coke : 1, milk : 2, pepsi : 3, bread : 4, beer : 5
        
        → 1 2 3 4 5 -1 1 4 5 -1 2 3 -1 4 5 -1 ~…
        
        ![파일에 저장된 항목집합들의 모습](https://prod-files-secure.s3.us-west-2.amazonaws.com/98684c9b-9ca0-4d4c-b4bb-bbf42f5dc5e8/09a5f1b2-c535-4127-8813-88918f09c259/Untitled.png)
        
        파일에 저장된 항목집합들의 모습
        
- 따라서 비용(cost)가 가장 중요한데, **cost = pass의 횟수**이다.
    
    pass : 파일의 처음부터 끝까지 읽어들이는 횟수, 디스크에 접근하는 횟수
    
    → one pass algorithm = 파일의 처음부터 끝까지 한번만 읽어서 원하는 ‘빈발 항목 집합을 다 찾아내는 것.
    

| Naive 알고리즘(1pass) | 선험적 알고리즘 (2pass) | PCY 알고리즘 (2pass) |
| --- | --- | --- |
| Pass1 - (1) 4byte 
만들 수 있는 모든 pair를 만든 다음 4byte씩 할당, 전체 파일을 읽으며 pair가 등장할때마다 count++ | Pass1
모든 항목들의 등장횟수를 센다. | Pass1
모든 항목들의 등장횟수를 세고, 남은 메모리에 버킷으로 채운다. pair가 등장할때 해시함수로 알맞은 버킷에 count++ |
| Pass1 - (2) 12byte
전체 파일을 읽을 때 등장하는 pair에 대해서만 [i, j, c]의 형태로 저장한다.   | Pass2
pass1의 항목들 중 빈발 항목에 대해서만 후보 pair를 만들고, 실제로 빈발한지 count해본다. | Pass2
비트맵에 1로 저장된 빈발버킷으로 해싱된 pair들 중, 각 항목이 빈발항목인 pair에 대해서만 실제로 빈발한지 count해본다. |

## Naive 알고리즘 (pair 찾기)

### ▶️ **접근1 : 4byte씩 모든 Pair**

- **가능한 모든 pair를 생성**하고, 각 pair당 4byte(int형)씩 할당한다. 이후 항목집합들에서 해당 pair를 발견할때마다 1개씩 count++ 해준다.
    
    전체 아이템의 개수가 n일 때, 총 pair는 n(n-1)/2개, 총 byte는 O(n^2) 이다.
    
- ex) 전체 아이템 = {m, c, p, b, j} 일때,
    
    가능한 모든 pair의 개수 = 5C2 = 10
    
    B1 = {m, c, b} 일 때, 등장할 수 있는 pair는 ‘mc’, ‘cb’, ‘bm’ 이므로 해당하는 pair에 맞는 메모리에 1씩 증가시켜 준다.
    
- 장점: 대부분의 pair들이 1번 이상씩 등장할 때 유리하다.
- 단점: 한번도 등장하지 않은 pair들이 많다면 각각 4byte씩 낭비된다.

### ▶️ **접근2 : 12byte씩 등장하는 Pair만**

- [i, j, c] = {i, j}쌍이 c번 등장했음을 알려주는 테이블 형태로 pair를 저장한다. 총 3개의 정수를 저장해야 하므로 pair당 12byte가 필요하다.
- 장점 : 전체 pair들 중 일부 pair만 등장할 때(전체 pair의 1/3 이하) 유리하다.
- 단점 : pair당 차지하는 공간의 크기가 크다 보니, 대부분의 pair가 등장할때는 오히려 접근1때보다 더 많은 메모리 공간을 필요로 할 수도 있다.

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/98684c9b-9ca0-4d4c-b4bb-bbf42f5dc5e8/ca728a9e-0e48-4a46-b1d6-5fbabc0e4239/Untitled.png)

## A-Priori (선험적) 알고리즘

- **2 Pass 알고리즘**으로, 디스크를 두번 읽어야 하므로 naive알고리즘보다는 **느리지만** 더 **효율적**이다.
- Key Idea - **monotonicity(단조성) : 항목집합 I가 빈발하다면, I의 모든 부분집합 역시 빈발하다.**

### Pass 1 : 빈발 Pair가 될 가능성이 없는 Pair들은 걸러낸다. (필터링)

- (pair가 아니고) 개별 항목들이 몇번씩 등장하는지 확인한다.
    
    따라서, pass1에서는 항목들의 “총 개수 * 4byte” 만큼의 메모리만 필요하다.
    
- 지지도 임계치(s)보다 적은 등장 횟수를 갖는 항목들은 걸러진다.
    
    ⇒ 단조성에 따라, 만약 항목1이 s번 보다 적게 등장했다면, 항목1과 짝을 이루는 어떤 pair들도 s번 이상 등장할 수 없다.
    

ex) [5][3]~~[1]~~[7]~~[2]~~[4]~~[1]~~ … ⇒ s=3 필터링 후, [5][3][7][4][6][4][8]

- 이때, 필터링을 통해 항목의 개수가 반으로 줄어들었다면, 면적은 1/4만큼 줄어들기 때문에 훨씬 효율적이다.

### Pass 2 : 빈발 항목들로 Pair 만들기

- 빈발 항목들로 pair를 만들어서, 빈발 항목 pair가 될 가능성이 있는 후보자(Candidate)를 만든 후,등장하는 모든 pair들을 세서, 빈발 pair가 되는지 확인한다.

### 빈발 triple 찾기 (k-tuples)

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/98684c9b-9ca0-4d4c-b4bb-bbf42f5dc5e8/0c33a94b-4ee3-4cba-ae69-cb9a6c08c759/Untitled.png)

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/98684c9b-9ca0-4d4c-b4bb-bbf42f5dc5e8/53bd6c58-72f8-40d8-80d3-c6f6f35d6d58/Untitled.png)

- 선험적 알고리즘에서, pass를 한번씩 추가할 때마다 한개씩 길어진 쌍을 찾을 수 있다.
- ex) 
[pass1]
    1. C1 = {{b} {c} {j} {m} {n} {p}} : 빈발 1-tuple 후보들
    2. C1의 항목들의 지지도를 센다. → 필터링
    3. L1 = {b,c,j,m} = {실제 2-tuple}
    
    [pass2]
    
    1. C2 = {{b,c}, {b,j}, {b,m}, {c,j}, {c,m}, {j,m}} : 빈발 2-tuple 후보들
    2. C2의 항목들의 지지도를 센다. → 필터링
    3. L2 = {{b,m} {b,c} {c,m} {c,j}}
    
    [pass3]
    
    1. C3 = {{b,c,m} ~~{b,c,j} {b,m,j} {c,m,j}~~} : 빈발 3-tuple 후보들
    2. C3의 항목들의 지지도를 센다. → 지지도에 의한 필터링, 단조성에 의한 필터링
        
        > 이때, 단조성에 의해 {b,c,j} {b,m,j} {c,m,j}는 고려할 필요가 없다.
        > 
        
        > **왜?** 
        {b, c, j}가 빈발 3-tuple이 되려면, {b,c}, {c,j}, {j,b} 모두 L2(빈발 2-tuple) 이었어야 한다. 하지만, {j,b}는 L2에 포함되지 않으므로 {b,c,j} 또한 빈발 3-tuple이 될 가능성이 없다. 
        마찬가지로 {b,m,j} {c,m,j} 도 빈발 3-tuple이 될 가능성이 없다.
        > 
    3. L3 = {{b,c,m}} 
    

## PCY 알고리즘

- 발생 배경 : 선험적 알고리즘의 경우, pass1에서 사용하지 않는 메모리의 크기가 너무 많다. 빈 메모리 공간을 활용하여 더 효율적인 빈발항목집합을 찾아보자!

> 선험적 알고리즘의 pass1 : 모든 항목들의 등장 횟수를 센다. 
선험적 알고리즘의 pass2 : 빈발 항목들로 pair를 만들고, 해당 pair가 빈발 pair인지 센다.
> 

### PCY 알고리즘의 pass1

: 선험적 알고리즘의 pass1 **+ 해시테이블로 버킷 카운트**

1. (남은) 메모리 공간에 만들 수 있는 최대 버킷을 만든다.
2. 모든 pair에 대해 등장할때마다 해시함수로 계산하고, 결과값을 버킷에 저장한다.
    
    이때, 하나의 버킷에는 여러개의 pair의 결과값이 저장될 수 있다.(pair의 전용버킷 아님)
    
3. 모든 해싱이 끝났을 때, 각 버킷이 몇번 카운트 되었는지 보다 각 버킷의 카운트가 s(threshold) 이상인지를 확인한다. (빈발버킷인지 확인)

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/98684c9b-9ca0-4d4c-b4bb-bbf42f5dc5e8/30e77c37-8169-4fee-8ca1-f03ed1a4765f/Untitled.png)

### PCY 알고리즘의 pass2

1. 해싱의 결과로 각 버킷이 빈발버킷인지의 여부를 비트맵으로 저장한다.
    
    → 4byte(버킷카운트)가 1bit(빈발여부)가 되므로 메모리크기가 1/32로 줄어든다.
    
2. 아래 두 조건을 모두 만족시키는 pair{i, j}들이 실제로 빈발 pair인지 센다.
    - **항목 i, j 모두 빈발 항목이다.**
    - **pair {i, j}**가 해싱된 버킷이 **빈발 버킷**이다.(비트맵 결과가 1이다.)

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/98684c9b-9ca0-4d4c-b4bb-bbf42f5dc5e8/8de36b81-50db-4c88-a6b0-1e242de8d259/Untitled.png)

### PCY 알고리즘의 관점

- 만약 버킷이 빈발 pair를 담고 있다면, 그 버킷은 빈발버킷일것이다.
    - 빈발버킷X : 해당 버킷으로 해싱된 pair(i, j)의 각 항목이 **빈발 항목일지라도**, 빈발버킷이 되지 않았다면 **빈발 pair가 아니다**.
    - 빈발버킷O : 해당 버킷으로 해싱된 pair가 여러개일 수도 있기 때문에, pair들은 빈발 pair일 가능성이 있다.

⇒ pass2에서 검사해야하는 pair들의 개수를 줄일 수 있다.

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/98684c9b-9ca0-4d4c-b4bb-bbf42f5dc5e8/ec6f5ae9-4998-49fb-bf92-c00daf0f1786/Untitled.png)

# 2Pass 이하의 빈발항목집합 찾기(단계한정알고리즘)

선험적 알고리즘, PCY 등은 k사이즈의 빈발항목집합을 찾기 위해서는 k번의 pass가 필요했다.

→ 더 적은 pass로는 불가한가?

## 랜덤 샘플링

: 전체 장바구니에서 랜덤샘플링을 진행한다. 표본의 크기가 줄어든 만큼 s도 동일비율로 줄인다.

> ex) 1000명 중, 500명 이상이 구입한 항목은? 
      [100명 랜덤샘플링] → 100명 중, 50명 이상이 구입한 항목은?
> 
- 문제점 : FP(위양성)는 방지할 수 있지만, FN(위음성)은 찾을 수 없다.
    
    pass1: 랜덤 샘플링으로 빈발 pair를 찾아낸다.
    
    pass2: pass1의 결과로 나온 빈발pair가 전체표본에서도 실제로 빈발한지 검사한다. → FP방지
    
    하지만, 실제로는 빈발 pair지만 운이 없어서 랜덤표본에 들어가지 못했던 pair(FN)가 있다면 pass2에서 검사조차 할 수 없기때문에 찾을 수 없다.
    
- 해결방안? : FN을 줄이기 위해 살짝 작은 threshold를 사용한다. (s/100 → s/125)
(하지만 운이 없다면 여전히 FN을 못찾을지도 모른다.)

⇒ SON알고리즘은 FN이 발생하지 않는다!

## SON 알고리즘

: 2pass 알고리즘으로, 반복적으로 장바구니 데이터의 일부를 메인메모리에 읽는다. (메모리를 여러번 읽고 쓰는 것은 pass에 count되지 않으므로, 적은 양을 읽어와서 여기서 찾을 수 있는 모든 것을 찾아낸다.)

- 랜덤샘플링과 SON알고리즘의 다른 점
    - 랜덤샘플링 : 전체 데이터 중 일부만 읽는다. (선택되지 않은 부분은 영원히 읽히지 않으므로 FN발생)
    - SON알고리즘 : 전체 데이터를 작은 부분씩(청크) 나누어 읽는다. (결과적으로 전체 데이터를 순차적으로 다 읽는다.)

### SON 알고리즘의 Pass1

전체 데이터를 청크로 분할한다. 각 청크는 전체 파일의 비율 ‘p’에 해당하고, 지지도 임계치가 s라면 ps를 임계치로 사용한다. 각 청크에서 발견된 모든 빈발항목집합을 디스크에 저장한다.

ex) 총 1000개의 장바구니가 있을 때, s = 100이다. 

p = 1/5이라면, 1개의 청크당 200개의 장바구니가 담겨있고, sp = 20이다.

### SON 알고리즘의 Pass2

모든 청크를 다 확인한 후, pass1에서 하나 이상의 청크에서 빈발했던 항목집합들이 전체 데이터에서도 실제로 빈발한지 확인한다.

- 그렇다면 SON 알고리즘에서는 FN이 발생하지 않는가?

> → YES!
만약 실제로는 빈발한 항목집합이 운이 없어 일부 청크에서는 빈발하지 못했다고 하더라도, 전체 등장 횟수는 정해져 있으므로 다른 청크에서는 빈발하게 등장이 확인된다.
> 

ex) s=100, p=1/5일때, 총 100번 등장하여 전체 항목에서 빈발항목인 A가 있다고 했을 때, 아래 표와 같이 일부 청크에서는 빈발하지 못할때도 있지만 결국 다른 청크에서 빈발항목으로 감지된다.

| 청크1 | 청크2 | 청크3 | 청크4 | 청크5 | 전체  |
| --- | --- | --- | --- | --- | --- |
| 10 | 0 | 0 | 30 | 60 | 100 |
| 25 | 15 | 20 | 20 | 20 | 100 |

## Toivonen 알고리즘

: 랜덤 샘플링을 했을 때, FN이 발생했는지 알 수 있다.

- **중간항목집합(immediate subsets)** : 정확하게 하나의 항목을 제외함으로써 구성되는 부분집합. 예를들어, {ABCD}의 중간항목집합은 {ABC} {ABD} {ACD} {BCD} 이다.
- **negative border** : 찾아낸 랜덤표본에서는 빈발하지 않지만, 전체표본에서 빈발표본이 될 확률이 높은 항목 집합을 추가해준다. negative border의 항목들이 모두 전체표본에서 빈발하다고 장담할 수는 없다. (FN을 찾아낸다.)

### 토이보넨 알고리즘의 Pass1

p의 크키로 랜덤샘플링을 수행하여, 찾아낸 랜덤표본에서의 빈발항목집합을 찾는다. 이때, s는 p보다 살짝 작은 비율로 조정해 준다. (예를 들어, p=1/100이었다면, s/125가 되게 해준다.) 

만약, 자기자신 집합은 빈발하지 않지만 자기자신 집합의 중간항목집합은 빈발한 항목집합이 있다면 **negative border**에 추가해준다.

### 토이보넨 알고리즘의 Pass2

pass1에서 찾아낸 빈발항목 후보집합이 전체표본에서도 실제로 빈발한지 확인한다. 또한, negative border에 감지된 항목집합들 또한 전체표본에서 빈발한지도 확인한다.

만약, negative border에 감지된 항목집합 중 실제로 빈발한 것이 있다면, 다시 pass1로 돌아가서 negative border에 감지된 항목집합 중 실제로 빈발한 것이 없는 랜덤표본을 찾을때까지 반복한다.(찾는데 오래걸릴수도 있다….)

### 토이보넨 알고리즘의 FN 증명

과연 토이보넨 알고리즘에서, 전체표본에서는 빈발하지만 랜덤표본에서는 빈발하지 않고 negative border에도 검출되지 않는 항목집합은 존재하지 않는가? (모든 FN을 찾을 수 있는가?)

**[가정]**
어떤 항목집합 **S**는 **전체 표본에서는 빈발**하지만, **샘플에서는 빈발하지 않고** **negative border에도 검출되지 않는다**고 하자. 

**[증명]**

항목집합 T는 샘플에서 빈발하지 않은 S의 모든 부분집합 중 크기가 가장 작은 부분집합이다. 

단조성에 의해 S의 부분집합인 T는 전체표본에서는 빈발하며, 샘플에서는 빈발하지 않고 negative border에도 감지되지 않는다.

T는 negative border에 반드시 감지되어야 하고, 실제로 negative border의 조건을 만족한다.

1. T는 샘플에서 빈발하지 않다.(T의 정의)
2. T의 중간항목집합은 샘플에서 빈발하다.

만약, T가 2번 조건을 만족하지 않아서 negative border가 아니라고 하자.

그렇다면 T의 중간항목집합들 중 샘플에서 빈발하지 않은 것들이 존재한다는 것인데, T의 중간항목집합은 T의 부분집합이고, T는 S의 부분집합이므로 T의 중간항목집합은 S의 부분집합이다.

그러나 T를 정의할 때, 샘플에서 빈발하지 않은 S의 부분집합 중 크기가 가장 작은 부분집합이라고 했는데 T의 중간항목집합 중 빈발하지 않은것이 존재한다면 모순이다.

그러므로 T는 2번 조건을 만족할수밖에 없고 negative border에 속한다. 즉, 전체표본에서는 빈발하지만 샘플에서는 빈발하지않고 negative border에서도 감지되는 항목(NF)은 존재하지 않는다.
